{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b84c0e4-6487-4362-a84b-6690e626746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d4dd36ba-47fb-4696-9d8a-dc86f6d8de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=np.load(\"../Downloads/9. Practical Project/Dataset/Primary categories - Train.npz\")\n",
    "data_test=np.load(\"../Downloads/9. Practical Project/Dataset/Primary categories - Test.npz\")\n",
    "data_validation=np.load(\"../Downloads/9. Practical Project/Dataset/Primary categories - Validation.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfa369-9234-42e9-9ea6-206ab92aded0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "709392b5-f213-4097-8ba4-8f6762e3e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train=data_train['images']\n",
    "label_train=data_train['labels']\n",
    "\n",
    "images_test=data_test['images']\n",
    "label_test=data_test['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9809cf-c159-4121-9ac5-e5052ab5769d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e2d082a6-820c-4e26-a669-54997c7d2f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_val=data_validation['images']\n",
    "label_val=data_validation['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c786adcf-9362-4eae-976a-41ee0d117e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train=images_train/255.0\n",
    "images_val=images_val/255.0\n",
    "images_test=images_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52932a59-b418-418a-a3de-d8e844f25d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=15\n",
    "BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a3654c46-b7fe-42d8-b975-1f439eeaaff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_FILTER_SIZE=hp.HParam('filter_size',hp.Discrete([3,5,7]))\n",
    "HP_FILTER_NUM=hp.HParam('filter_number',hp.Discrete([32,64,96,128]))\n",
    "\n",
    "METRIC_ACCURACY='accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer(r'logs/Model 1/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_FILTER_SIZE,HP_FILTER_NUM],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY,display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab10640-dc5e-45e3-8ac9-6c63dd6ebb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams,session_num):\n",
    "    model=tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM],hparams[HP_FILTER_SIZE],activation='relu',input_shape=(120,90,3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM],3,activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "    loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(optimizer='adam',loss=loss_fn,metrics=['accuracy'])\n",
    "    log_dir=\"Logs\\\\Model 1\\\\fit]\\\\\"+\"run-{}\".format(sesssession_num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e076fff6-2d5b-4a2f-b17f-896f48fb8368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f66d3-c63a-46a6-bf12-954a64fabb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams, session_num):\n",
    "    \n",
    "    # Outlining the model/architecture of our CNN\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], hparams[HP_FILTER_SIZE], activation='relu', input_shape=(120,90,3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "    \n",
    "    # Defining the loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    # Defining the logging directory\n",
    "    log_dir = \"Logs\\\\MOdel 1\\\\fit\\\\\" + \"run-{}\".format(session_num)\n",
    "    \n",
    "    \n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "          cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "          class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "    \n",
    "    \n",
    "    \n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    # Defining a file writer for Confusion Matrix logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')     \n",
    "    \n",
    "    \n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(label_val, test_pred)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Glasses/Sunglasses', 'Trousers/Jeans', 'Shoes'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define the Tensorboard and Confusion Matrix callbacks.\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "    \n",
    "    # Defining early stopping to prevent overfitting\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        label_train,\n",
    "        epochs = EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data = (images_val,label_val),\n",
    "        verbose = 2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Evaluating the model's performance on the validation set\n",
    "    _, accuracy = model.evaluate(images_val,label_val)\n",
    "    \n",
    "    # Saving the current model for future reference\n",
    "    # Saving the current model for future reference\n",
    "    model.save(r\"saved_models\\\\Model 1\\\\Run-{}\".format(session_num))\n",
    " # Doubling backslashes\n",
    "\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a25f49-eeb2-451a-80ac-1ff4822fa7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cadd8bc-b434-44d9-87a2-87a949a77ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dcfbf9-148a-418c-a731-88504d56264f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ecb42-46c6-4754-b3d1-3181ccf27f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(log_dir, hparams, session_num):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7abc461-6c74-47cb-9a68-82072653a597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530e534-5264-4587-93c1-0d715da6a843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a56263-04a9-4f94-b404-a18524e1bbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "65992c52-b11b-4cb7-b5f2-b6bbdc0242cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-1\n",
      "{'filter_size': 3, 'filter_number': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bizmotion/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "203/203 - 47s - 231ms/step - accuracy: 0.9806 - loss: 0.0709 - val_accuracy: 0.9994 - val_loss: 0.0042\n",
      "Epoch 2/15\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "203/203 - 80s - 392ms/step - accuracy: 0.9982 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 3/15\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "203/203 - 46s - 228ms/step - accuracy: 0.9987 - loss: 0.0090 - val_accuracy: 0.9969 - val_loss: 0.0122\n",
      "Epoch 4/15\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "203/203 - 45s - 223ms/step - accuracy: 0.9996 - loss: 0.0036 - val_accuracy: 0.9981 - val_loss: 0.0068\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0024\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=saved_models\\\\Model 1\\\\Run-1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--- Starting trial: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m run_name)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m({h\u001b[38;5;241m.\u001b[39mname: hparams[h] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hparams})\n\u001b[0;32m---> 14\u001b[0m run(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogs/Model 1/hparam_tuning/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m run_name, hparams, session_num)\n\u001b[1;32m     16\u001b[0m session_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[104], line 5\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(log_dir, hparams, session_num)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mcreate_file_writer(log_dir)\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m      4\u001b[0m     hp\u001b[38;5;241m.\u001b[39mhparams(hparams)  \u001b[38;5;66;03m# record the values used in this trial\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m train_test_model(hparams, session_num)\n\u001b[1;32m      6\u001b[0m     tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mscalar(METRIC_ACCURACY, accuracy, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[99], line 125\u001b[0m, in \u001b[0;36mtrain_test_model\u001b[0;34m(hparams, session_num)\u001b[0m\n\u001b[1;32m    121\u001b[0m _, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(images_val,label_val)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Saving the current model for future reference\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Saving the current model for future reference\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_models\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mModel 1\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mRun-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(session_num))  \u001b[38;5;66;03m# Doubling backslashes\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_api.py:114\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39msave_model_to_hdf5(\n\u001b[1;32m    112\u001b[0m         model, filepath, overwrite, include_optimizer\n\u001b[1;32m    113\u001b[0m     )\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filepath extension for saving. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease add either a `.keras` extension for the native Keras \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat (recommended) or a `.h5` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `model.export(filepath)` if you want to export a SavedModel \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor use with TFLite/TFServing/etc. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=saved_models\\\\Model 1\\\\Run-1."
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "\n",
    "for filter_size in HP_FILTER_SIZE.domain.values:\n",
    "    for filter_num in HP_FILTER_NUM.domain.values:\n",
    "\n",
    "        hparams = {\n",
    "            HP_FILTER_SIZE: filter_size,\n",
    "            HP_FILTER_NUM: filter_num\n",
    "        }\n",
    "\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('Logs/Model 1/hparam_tuning/' + run_name, hparams, session_num)\n",
    "\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b3b7f9ef-a59e-46a7-8c60-d50ced12b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-db8f28375b4fd16e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-db8f28375b4fd16e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs/Model 1/hrapam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff45b71-6c86-4382-ac38-55dd00f81d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9b418-afcc-4f48-91cf-5e39429bfe46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd5e56-62a9-4988-9c14-94f202f83b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eabd39-3377-48e2-93f8-0b5494186938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de8704-93f8-4a17-abfb-4aaa2adf2a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57f894-950b-42ba-a587-b27c2d4ffe24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77eed41-cad2-4b36-89d2-3106b0c549cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d71db79-85c1-4f38-b469-ce50a3d51996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f16024-e791-452a-aeb1-8d65472521cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea1a84-8ed6-40a4-9e5a-c2a3d7fdfc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
